{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "from queue import PriorityQueue\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Usage: display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from images_evaluation\n",
      "images_valid\n",
      "images_valid\n",
      "images_valid\n",
      "images_valid\n",
      "images_valid\n",
      "images_valid\n",
      "images_valid\n",
      "images_valid\n",
      "images_valid\n",
      "images_valid\n",
      "images_valid\n",
      "images_test\n",
      "images_test\n",
      "images_test\n",
      "images_test\n",
      "images_test\n",
      "images_test\n",
      "images_test\n",
      "images_test\n",
      "images_test\n",
      "Reading from images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n",
      "images_background\n"
     ]
    }
   ],
   "source": [
    "data_path = './data'\n",
    "dataset = {}\n",
    "\n",
    "set_types = ['images_background', 'images_valid', 'images_test']\n",
    "alpha_chars = {}\n",
    "for set_type in set_types:\n",
    "    alpha_chars[set_type] = set()\n",
    "    dataset[set_type] = {}\n",
    "\n",
    "for set_type in os.listdir(data_path):    \n",
    "    print('Reading from {}'.format(set_type))\n",
    "    set_path = os.path.join(data_path, set_type)\n",
    "    for alpha_idx, alphabet in enumerate(os.listdir(set_path)):\n",
    "        if alpha_idx > 10 and set_type == 'images_evaluation':\n",
    "            new_set_type = 'images_test' # Test\n",
    "        elif set_type == 'images_evaluation':\n",
    "            new_set_type = 'images_valid' # Valid\n",
    "        else:\n",
    "            new_set_type = set_type # Train\n",
    "        print(new_set_type)\n",
    "        dataset[new_set_type][alphabet] = {}\n",
    "        alphabet_path = os.path.join(set_path, alphabet)\n",
    "        # print(alphabet)\n",
    "        for _, character in enumerate(os.listdir(alphabet_path)):\n",
    "            alpha_chars[new_set_type].update(['__'.join([alphabet, character])])\n",
    "            dataset[new_set_type][alphabet][character] = []\n",
    "            character_path = os.path.join(alphabet_path, character)\n",
    "            for k, sample in enumerate(os.listdir(character_path)):\n",
    "                img = Image.open(os.path.join(character_path, sample))\n",
    "                dataset[new_set_type][alphabet][character] += [np.asarray(img, np.uint8)]\n",
    "                img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABpCAAAAAAc6VLmAAABO0lEQVR4nO2Z2w4DIQhEsen//zJ9aNJLBFlG1y7N8GrqYQDRsk1lk912gUgqQrov2aWJiARVvFBTa7tIAWtN9N4scaN4lPTpbZCQZq8jmloHUxnnSATOU7exqvqLMyQr+TqO6tKKUE9PhvTy97WVk/hp0hcyTr9hUJ6g2xMibdMEgSb6XjaEp9xPpmiY5Ejylf7j7U7S9UhWmRfW5B6owppIIum3JKNJVNbkNYnKmgqT0s/La2s68nrtJeOasuHL/yfE3v8hCdlW7R8NSaj7pg3yFMyBsn5ce+o2HAbgpGWz5yh6I1BO2EDT4kk6WBFPL1KiTqg9h4+SotD269e+NUgiybPM0V09oTqBlDaSSCpKShzdMpq2kFQl1ZNmvnTlWl+F6JFE0kFzzln2qyxupaNHEkkkkUQSSdP2APP8J+1H3HgpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=105x105 at 0x7F0854375668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABpCAAAAAAc6VLmAAAA9UlEQVR4nO3a3Q7CIAyGYWq8/1vGA7O5GSj9+JlxeTnxYEmf0iKQbJbTReNxFYSE9DWeE2LY+6fxfxHmZGYRcFyyZjA/E7FPjby9x+qK6Kcsvu/5jd+Majx9lVfS3oRqswRpj+U/rj0XqpdKJbJCDuWQWvUaJXKzFvv0KVHR8ih1RRzq1tgyRqWUD3lLVsdefrKWSmdrrdRldZ9PWSpdGjtztXkNnbnSvO54Y0FCQkJCWjXK55N2msYuwnPmFMnsjn2aI0X6VF4Rwq0nvHj+rXpISEhISEhISEhISEi/krT3T4F49dd7fB+BhISEhISEhIQ0ZbwAWwQi3oH9/BcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=105x105 at 0x7F07CD61CF28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABpCAAAAAAc6VLmAAAA8ElEQVR4nO3Z0Q6CMAyF4db4/q88L0wIZqDnrEBA/l4u2C9rZzMxWxwUj6MgJCQkpJNIT+WhjIjoR/HK8kroe8qUHy1KVcvr04Il6+6JGKdS7eiUsHVrWgp5T20hn3UzMKq3mjelo+L06U1ltxJSs4ozwqhfdRrplCUtpd1hGjn8PpIantQijPlTkSqBhISEhHR96etvDevmWJI+wWKMVG9Mvt2J6K/Hs+VNpT5x4XD8Y5+QkLaW1K/YRnsSxsaVqoeEhIT0M/Z/k2jEud+63eBe3kIqofwfwPSB0Xu5LQ3HpfqEhISEhISEhISEdKj0ArDiHdhMEGJ+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=105x105 at 0x7F07CD61CF28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "(105, 105)\n"
     ]
    }
   ],
   "source": [
    "display(Image.fromarray(dataset['images_background']['Korean']['character06'][0]*255))\n",
    "display(Image.fromarray(dataset['images_background']['Korean']['character06'][5]*255))\n",
    "display(Image.fromarray(dataset['images_background']['Korean']['character06'][15]*255))\n",
    "\n",
    "print(len(dataset['images_background']['Korean']['character01']))\n",
    "print(dataset['images_background']['Korean']['character01'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 2, 11025) (30000,)\n",
      "(10000, 2, 11025) (10000,)\n",
      "(10000, 2, 11025) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def get_drawers(set_type, alpha, char, diff=False, alpha2=None, char2=None):\n",
    "    drawer1 = np.random.randint(len(dataset[set_type][alpha][char]))\n",
    "    drawer2 = drawer1\n",
    "    \n",
    "    if not diff:\n",
    "        while drawer2 == drawer1:\n",
    "            drawer2 = np.random.randint(len(dataset[set_type][alpha][char]))\n",
    "    else:\n",
    "        while drawer2 == drawer1:\n",
    "            drawer2 = np.random.randint(len(dataset[set_type][alpha2][char2]))\n",
    "    assert drawer1 != drawer2\n",
    "    \n",
    "    return drawer1, drawer2\n",
    "\n",
    "def get_random_dataset(set_type, set_size, shuffle_dataset=True):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for _ in range(set_size):\n",
    "        same_alpha, same_char = random.sample(alpha_chars[set_type], 1)[0].split('__')\n",
    "        drawer1, drawer2 = get_drawers(set_type, same_alpha, same_char)\n",
    "        inputs.append([dataset[set_type][same_alpha][same_char][drawer1].flatten(), \n",
    "                           dataset[set_type][same_alpha][same_char][drawer2].flatten()])\n",
    "        labels.append(1)\n",
    "\n",
    "        diff1_alpha, diff1_char = random.sample(alpha_chars[set_type], 1)[0].split('__')\n",
    "        diff2_alpha = diff1_alpha\n",
    "        diff2_char = diff1_char\n",
    "        while diff2_alpha == diff1_alpha and diff2_char == diff1_char:\n",
    "            diff2_alpha, diff2_char = random.sample(alpha_chars[set_type], 1)[0].split('__')\n",
    "        drawer1, drawer2 = get_drawers(set_type, diff1_alpha, diff1_char, True, diff2_alpha, diff2_char)\n",
    "        inputs.append([dataset[set_type][diff1_alpha][diff1_char][drawer1].flatten(), \n",
    "                           dataset[set_type][diff2_alpha][diff2_char][drawer2].flatten()])\n",
    "        labels.append(0)\n",
    "        \n",
    "    # Shuffle dataset\n",
    "    combined = list(zip(inputs, labels))\n",
    "    random.shuffle(combined)\n",
    "    \n",
    "    return zip(*combined)\n",
    "\n",
    "train_inputs, train_labels = get_random_dataset('images_background', 15000)\n",
    "valid_inputs, valid_labels = get_random_dataset('images_valid', 5000)\n",
    "test_inputs, test_labels = get_random_dataset('images_test', 5000)\n",
    "\n",
    "print(np.array(train_inputs).shape, np.array(train_labels).shape)\n",
    "print(np.array(valid_inputs).shape, np.array(valid_labels).shape)\n",
    "print(np.array(test_inputs).shape, np.array(test_labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABpCAAAAAAc6VLmAAABoUlEQVR4nO2Y0ZLDIAhFpbP//8vuQ5tENwr3CsmmM/iQmZqGIwgISi03jdddoCQlKUlJSlKSkpSkJP0L6Qf4j5RSirsCfaD15DaSG0VYz4lCSJszzFHIIiCdbL8Tm4VZr75ZmjgTFeflFgol2UpZg9RpjIIWAJPmXgF4A0Wa2k8+7ywHRTKsNmR7mpFA7JPqFHbIBXk5cKYwpKm4ihxeDzyfxoMIZR+JyRkR1sNKDJ7UpAQhQC6duHxLkWpHkG4yltRJZU8Q0noHSk4zsaSdQoNWPYIHLZIWQDSpTn9Ek1rpXPvhiFyyz6FJexixDdW6ThdHbiufRHkqS7DQWyL9TaqXnYQ7CCpRHKRWg3qesr7GVzc23QW5fLJ8WCv2lqDZIdKAKGkkj0NBvcYhq9+VGu3lx73RePvDOrWjRTqBQk9CUZM30WhbpK231NePoPTIBQ4juKQA71jsV6Zampdjy0VdXdEJbf/BAJ6T5POwPTmof0LEQKi57/G3UTowsnfX1/Y1twTdWLUeXZQYHxB1hHN85z4lKUlJSlKSkpSkJ5B+AWUiTdbQcvZHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=105x105 at 0x7F08542EE668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABpCAAAAAAc6VLmAAABb0lEQVR4nO3Y24rDMAwEULv0/3/Zfegtjm8zkhISGMPC0mV9osaVJs0lnbQeZ0GSJEmSJEmSpJPW0/fvOSU0iPhqyp8fZE1ryinh17xarprQckBpvB0FITUtNow8Edy1m6RS1hR8YBY1AVSQNKEyyS/v06wq6qO2PhETiuhF0NnrU3n7tyAp6FhA3WhIMTcK63stxRcIdtg9ZXgn0V5eU7l6MVaqKAtEzKc/ZYIMOeJ7i9hZTMzcUu1ND31qupfur0dIrvRCJhYHZc1Gh/WIFmAH4WWfAKqhFD3d21VsFCX9trZQjPSODWVLEZb17JX9C5FSnVFoCpf2YYilHJ8nkoKlTr7jKFTqBkmK8nUjhgKlUTYmKKam3nDCKUya7ANTTGLxUQHzCXkajpHA1n7VmTtaSFHOb93WQIjUCNM0SEjLS5/Hzoh3D3HCJCBFh0hQWs9Ypu/fI+p5AJQC1t16hCRJkiRJkiRJkiRJku4hvQCPl0fg9WgIfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=105x105 at 0x7F08542EE780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Kannada\n",
      "dict_keys(['character01', 'character19', 'character40', 'character09', 'character37', 'character39', 'character11', 'character34', 'character33', 'character13', 'character35', 'character38', 'character25', 'character04', 'character23', 'character30', 'character22', 'character02', 'character21', 'character15', 'character29', 'character12', 'character27', 'character07', 'character16', 'character31', 'character06', 'character10', 'character41', 'character24', 'character20', 'character08', 'character18', 'character14', 'character32', 'character28', 'character26', 'character17', 'character36', 'character03', 'character05'])\n",
      "6 15\n",
      "character01\n",
      "20\n",
      "[[1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " ...\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "sample_idx = np.random.randint(len(train_inputs))\n",
    "display(Image.fromarray(np.reshape(train_inputs[sample_idx][0]*255, (105, 105))))\n",
    "display(Image.fromarray(np.reshape(train_inputs[sample_idx][1]*255, (105, 105))))\n",
    "print(train_labels[sample_idx])\n",
    "\n",
    "for alpha, char_set in dataset['images_test'].items():\n",
    "    print(alpha)\n",
    "    print(char_set.keys())\n",
    "    \n",
    "    drawer1 = np.random.randint(20)\n",
    "    drawer2 = drawer1\n",
    "    while drawer2 == drawer1:\n",
    "        drawer2 = np.random.randint(20)\n",
    "    \n",
    "    print(drawer1, drawer2)\n",
    "    \n",
    "    for char, samples in char_set.items():\n",
    "        print(char)\n",
    "        print(len(samples))\n",
    "        # Get two outputs per samples\n",
    "        print(samples[0])\n",
    "        break\n",
    "    \n",
    "    break\n",
    "    # Find most similar outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=10, padding=0),\n",
    "            # nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=7, padding=0),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=4, padding=0),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, padding=0),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.ReLU())\n",
    "        self.fc = nn.Linear(9216, 4096)\n",
    "        self.distance_fc = nn.Linear(4096, 1)\n",
    "    \n",
    "    def siamese_net(self, inputs):\n",
    "        inputs = inputs.view(-1, 1, 105, 105)\n",
    "        out = self.layer1(inputs)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        fc = self.fc(out.view(out.size(0), -1))\n",
    "        return fc\n",
    "    \n",
    "    def distance_layer(self, input1, input2):\n",
    "        return F.sigmoid(self.distance_fc(torch.abs(input1 - input2))).squeeze(1)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        out1 = self.siamese_net(x1)\n",
    "        out2 = self.siamese_net(x2)\n",
    "        # print(out1.size())\n",
    "        # print(out2.size())\n",
    "        distance = self.distance_layer(out1, out2)\n",
    "        # print(distance.size())\n",
    "        \n",
    "        return distance, out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atemayar_Qelisayer character01 character10 0.49790915846824646\n",
      "Atemayar_Qelisayer character19 character10 0.49783775210380554\n",
      "Atemayar_Qelisayer character09 character03 0.4975956082344055\n",
      "Atemayar_Qelisayer character11 character10 0.497103750705719\n",
      "Atemayar_Qelisayer character13 character16 0.49747857451438904\n",
      "Atemayar_Qelisayer character23 character21 0.49777549505233765\n",
      "Atemayar_Qelisayer character22 character21 0.49730628728866577\n",
      "Atemayar_Qelisayer character02 character10 0.4980393350124359\n",
      "Atemayar_Qelisayer character21 character19 0.4969276487827301\n",
      "Atemayar_Qelisayer character15 character26 0.4974838197231293\n",
      "Atemayar_Qelisayer character12 character22 0.49794626235961914\n",
      "Atemayar_Qelisayer character07 character26 0.4977181851863861\n",
      "Atemayar_Qelisayer character16 character16 0.4969179928302765\n",
      "Atemayar_Qelisayer character06 character10 0.49733033776283264\n",
      "Atemayar_Qelisayer character10 character11 0.4977189004421234\n",
      "Atemayar_Qelisayer character03 character22 0.49790099263191223\n",
      "Atemayar_Qelisayer character24 character12 0.4971843659877777\n",
      "Atemayar_Qelisayer character14 character06 0.497624009847641\n",
      "Atemayar_Qelisayer character08 character22 0.49739331007003784\n",
      "Atemayar_Qelisayer character18 character10 0.4982414245605469\n",
      "Atemayar_Qelisayer character20 character01 0.4971317946910858\n",
      "Atemayar_Qelisayer character25 character10 0.4976736605167389\n",
      "Atemayar_Qelisayer character26 character23 0.4972502589225769\n",
      "Atemayar_Qelisayer character17 character10 0.49753090739250183\n",
      "Atemayar_Qelisayer character04 character26 0.4969903826713562\n",
      "Atemayar_Qelisayer character05 character10 0.4977349638938904\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN().cuda()\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-1, momentum=0.5)\n",
    "\n",
    "num_epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    cnn.train(True)\n",
    "    '''\n",
    "    for train_idx in range(0, len(train_inputs), batch_size):\n",
    "        batch_inputs = train_inputs[train_idx:train_idx+batch_size]\n",
    "        batch_input1 = [b[0] for b in batch_inputs]\n",
    "        batch_input2 = [b[1] for b in batch_inputs]\n",
    "        batch_labels = train_labels[train_idx:train_idx+batch_size]\n",
    "        # print(np.array(batch_input1).shape)\n",
    "        # print(np.array(batch_input2).shape)\n",
    "        # print(np.array(batch_label).shape)\n",
    "        input1 = Variable(torch.Tensor(np.array(batch_input1).astype(np.float32))).cuda(0)\n",
    "        input2 = Variable(torch.Tensor(np.array(batch_input2).astype(np.float32))).cuda(0)\n",
    "        labels = Variable(torch.Tensor(np.array(batch_labels).astype(np.float32))).cuda(0)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _, _ = cnn(input1, input2)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (train_idx) % (batch_size * 30) == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, train_idx+1, len(train_inputs), loss.data[0]))\n",
    "    \n",
    "    # Validation\n",
    "    cnt = 0\n",
    "    acc = 0.\n",
    "    losses = 0.\n",
    "    cnn.train(False)\n",
    "    for valid_idx in range(0, len(valid_inputs), batch_size):\n",
    "        batch_inputs = valid_inputs[valid_idx:valid_idx+batch_size]\n",
    "        batch_input1 = [b[0] for b in batch_inputs]\n",
    "        batch_input2 = [b[1] for b in batch_inputs]\n",
    "        batch_labels = valid_labels[valid_idx:valid_idx+batch_size]\n",
    "        # print(np.array(batch_input1).shape)\n",
    "        # print(np.array(batch_input2).shape)\n",
    "        # print(np.array(batch_label).shape)\n",
    "        input1 = Variable(torch.Tensor(np.array(batch_input1).astype(np.float32))).cuda(0)\n",
    "        input2 = Variable(torch.Tensor(np.array(batch_input2).astype(np.float32))).cuda(0)\n",
    "        labels = Variable(torch.Tensor(np.array(batch_labels).astype(np.float32))).cuda(0)\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        outputs, _, _ = cnn(input1, input2)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        outputs = [int(k > 0.5) for k in outputs.data.tolist()]\n",
    "        acc += sum([o == l for o, l in zip(outputs, batch_labels)])/input1.size(0)\n",
    "        losses += loss.data[0]\n",
    "        cnt += 1\n",
    "        \n",
    "    print('Validation acc:{} loss: {}'.format(acc/cnt, losses/cnt))\n",
    "    '''\n",
    "    \n",
    "    for alpha, char_set in dataset['images_test'].items():\n",
    "        # Select two drawers\n",
    "        drawer1 = np.random.randint(20)\n",
    "        drawer2 = drawer1\n",
    "        while drawer2 == drawer1:\n",
    "            drawer2 = np.random.randint(20)\n",
    "        \n",
    "        sim_dict = {}\n",
    "        for char1, samples1 in char_set.items():\n",
    "            sim_dict[char1] = PriorityQueue()\n",
    "            for char2, samples2 in char_set.items():\n",
    "                input1 = Variable(torch.Tensor(np.array([samples1[drawer1]]).astype(np.float32))).cuda(0)\n",
    "                input2 = Variable(torch.Tensor(np.array([samples2[drawer2]]).astype(np.float32))).cuda(0)\n",
    "                distance, _, _ = cnn(input1, input2)\n",
    "                sim_dict[char1].put((-distance.data[0], char2))\n",
    "            \n",
    "            score, predicted = sim_dict[char1].get()\n",
    "            if alpha == 'Atemayar_Qelisayer':\n",
    "                print(alpha, char1, predicted, -score)\n",
    "            # Get two outputs per samples\n",
    "            # print(samples[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
