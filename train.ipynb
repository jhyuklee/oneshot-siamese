{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "from queue import PriorityQueue\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Usage: display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from images_evaluation\n",
      "images_valid Mongolian\n",
      "images_valid Syriac_(Serto)\n",
      "images_valid Glagolitic\n",
      "images_valid Keble\n",
      "images_valid Old_Church_Slavonic_(Cyrillic)\n",
      "images_valid Malayalam\n",
      "images_valid Aurek-Besh\n",
      "images_valid Tibetan\n",
      "images_valid Oriya\n",
      "images_valid Manipuri\n",
      "images_valid Ge_ez\n",
      "images_test Atlantean\n",
      "images_test Sylheti\n",
      "images_test Tengwar\n",
      "images_test Atemayar_Qelisayer\n",
      "images_test Kannada\n",
      "images_test Avesta\n",
      "images_test Gurmukhi\n",
      "images_test Angelic\n",
      "images_test ULOG\n",
      "Reading from images_background\n",
      "images_background Korean\n",
      "images_background Ojibwe_(Canadian_Aboriginal_Syllabics)\n",
      "images_background Asomtavruli_(Georgian)\n",
      "images_background Braille\n",
      "images_background Latin\n",
      "images_background Blackfoot_(Canadian_Aboriginal_Syllabics)\n",
      "images_background Inuktitut_(Canadian_Aboriginal_Syllabics)\n",
      "images_background Mkhedruli_(Georgian)\n",
      "images_background Armenian\n",
      "images_background Tifinagh\n",
      "images_background Futurama\n",
      "images_background N_Ko\n",
      "images_background Sanskrit\n",
      "images_background Greek\n",
      "images_background Bengali\n",
      "images_background Hebrew\n",
      "images_background Burmese_(Myanmar)\n",
      "images_background Cyrillic\n",
      "images_background Alphabet_of_the_Magi\n",
      "images_background Tagalog\n",
      "images_background Anglo-Saxon_Futhorc\n",
      "images_background Early_Aramaic\n",
      "images_background Grantha\n",
      "images_background Japanese_(katakana)\n",
      "images_background Malay_(Jawi_-_Arabic)\n",
      "images_background Syriac_(Estrangelo)\n",
      "images_background Arcadian\n",
      "images_background Balinese\n",
      "images_background Gujarati\n",
      "images_background Japanese_(hiragana)\n"
     ]
    }
   ],
   "source": [
    "data_path = './data'\n",
    "dataset = {}\n",
    "\n",
    "set_types = ['images_background', 'images_valid', 'images_test']\n",
    "alpha_chars = {}\n",
    "for set_type in set_types:\n",
    "    alpha_chars[set_type] = set()\n",
    "    dataset[set_type] = {}\n",
    "\n",
    "for set_type in os.listdir(data_path):    \n",
    "    print('Reading from {}'.format(set_type))\n",
    "    set_path = os.path.join(data_path, set_type)\n",
    "    for alpha_idx, alphabet in enumerate(os.listdir(set_path)):\n",
    "        if alpha_idx > 10 and set_type == 'images_evaluation':\n",
    "            new_set_type = 'images_test' # Test\n",
    "        elif set_type == 'images_evaluation':\n",
    "            new_set_type = 'images_valid' # Valid\n",
    "        else:\n",
    "            new_set_type = set_type # Train\n",
    "        print(new_set_type, alphabet)\n",
    "        dataset[new_set_type][alphabet] = {}\n",
    "        alphabet_path = os.path.join(set_path, alphabet)\n",
    "        # print(alphabet)\n",
    "        for _, character in enumerate(os.listdir(alphabet_path)):\n",
    "            alpha_chars[new_set_type].update(['__'.join([alphabet, character])])\n",
    "            dataset[new_set_type][alphabet][character] = []\n",
    "            character_path = os.path.join(alphabet_path, character)\n",
    "            for k, sample in enumerate(os.listdir(character_path)):\n",
    "                img = Image.open(os.path.join(character_path, sample))\n",
    "                dataset[new_set_type][alphabet][character] += [np.asarray(img, np.uint8)]\n",
    "                img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABpCAAAAAAc6VLmAAABO0lEQVR4nO2Z2w4DIQhEsen//zJ9aNJLBFlG1y7N8GrqYQDRsk1lk912gUgqQrov2aWJiARVvFBTa7tIAWtN9N4scaN4lPTpbZCQZq8jmloHUxnnSATOU7exqvqLMyQr+TqO6tKKUE9PhvTy97WVk/hp0hcyTr9hUJ6g2xMibdMEgSb6XjaEp9xPpmiY5Ejylf7j7U7S9UhWmRfW5B6owppIIum3JKNJVNbkNYnKmgqT0s/La2s68nrtJeOasuHL/yfE3v8hCdlW7R8NSaj7pg3yFMyBsn5ce+o2HAbgpGWz5yh6I1BO2EDT4kk6WBFPL1KiTqg9h4+SotD269e+NUgiybPM0V09oTqBlDaSSCpKShzdMpq2kFQl1ZNmvnTlWl+F6JFE0kFzzln2qyxupaNHEkkkkUQSSdP2APP8J+1H3HgpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=105x105 at 0x7FC39D803080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABpCAAAAAAc6VLmAAAA9UlEQVR4nO3a3Q7CIAyGYWq8/1vGA7O5GSj9+JlxeTnxYEmf0iKQbJbTReNxFYSE9DWeE2LY+6fxfxHmZGYRcFyyZjA/E7FPjby9x+qK6Kcsvu/5jd+Majx9lVfS3oRqswRpj+U/rj0XqpdKJbJCDuWQWvUaJXKzFvv0KVHR8ih1RRzq1tgyRqWUD3lLVsdefrKWSmdrrdRldZ9PWSpdGjtztXkNnbnSvO54Y0FCQkJCWjXK55N2msYuwnPmFMnsjn2aI0X6VF4Rwq0nvHj+rXpISEhISEhISEhISEi/krT3T4F49dd7fB+BhISEhISEhIQ0ZbwAWwQi3oH9/BcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=105x105 at 0x7FC39D803048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABpCAAAAAAc6VLmAAAA8ElEQVR4nO3Z0Q6CMAyF4db4/q88L0wIZqDnrEBA/l4u2C9rZzMxWxwUj6MgJCQkpJNIT+WhjIjoR/HK8kroe8qUHy1KVcvr04Il6+6JGKdS7eiUsHVrWgp5T20hn3UzMKq3mjelo+L06U1ltxJSs4ozwqhfdRrplCUtpd1hGjn8PpIantQijPlTkSqBhISEhHR96etvDevmWJI+wWKMVG9Mvt2J6K/Hs+VNpT5x4XD8Y5+QkLaW1K/YRnsSxsaVqoeEhIT0M/Z/k2jEud+63eBe3kIqofwfwPSB0Xu5LQ3HpfqEhISEhISEhISEdKj0ArDiHdhMEGJ+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=105x105 at 0x7FC39D803080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "(105, 105)\n"
     ]
    }
   ],
   "source": [
    "display(Image.fromarray(dataset['images_background']['Korean']['character06'][0]*255))\n",
    "display(Image.fromarray(dataset['images_background']['Korean']['character06'][5]*255))\n",
    "display(Image.fromarray(dataset['images_background']['Korean']['character06'][15]*255))\n",
    "\n",
    "print(len(dataset['images_background']['Korean']['character01']))\n",
    "print(dataset['images_background']['Korean']['character01'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 2, 11025) (30000,)\n",
      "(10000, 2, 11025) (10000,)\n",
      "(10000, 2, 11025) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def get_drawers(set_type, alpha, char, diff=False, alpha2=None, char2=None):\n",
    "    drawer1 = np.random.randint(len(dataset[set_type][alpha][char]))\n",
    "    drawer2 = drawer1\n",
    "    \n",
    "    if not diff:\n",
    "        while drawer2 == drawer1:\n",
    "            drawer2 = np.random.randint(len(dataset[set_type][alpha][char]))\n",
    "    else:\n",
    "        while drawer2 == drawer1:\n",
    "            drawer2 = np.random.randint(len(dataset[set_type][alpha2][char2]))\n",
    "    assert drawer1 != drawer2\n",
    "    \n",
    "    return drawer1, drawer2\n",
    "\n",
    "def get_random_dataset(set_type, set_size, shuffle_dataset=True):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for _ in range(set_size):\n",
    "        same_alpha, same_char = random.sample(alpha_chars[set_type], 1)[0].split('__')\n",
    "        drawer1, drawer2 = get_drawers(set_type, same_alpha, same_char)\n",
    "        inputs.append([dataset[set_type][same_alpha][same_char][drawer1].flatten(), \n",
    "                           dataset[set_type][same_alpha][same_char][drawer2].flatten()])\n",
    "        labels.append(1)\n",
    "\n",
    "        diff1_alpha, diff1_char = random.sample(alpha_chars[set_type], 1)[0].split('__')\n",
    "        diff2_alpha = diff1_alpha\n",
    "        diff2_char = diff1_char\n",
    "        while diff2_alpha == diff1_alpha and diff2_char == diff1_char:\n",
    "            diff2_alpha, diff2_char = random.sample(alpha_chars[set_type], 1)[0].split('__')\n",
    "        drawer1, drawer2 = get_drawers(set_type, diff1_alpha, diff1_char, True, diff2_alpha, diff2_char)\n",
    "        inputs.append([dataset[set_type][diff1_alpha][diff1_char][drawer1].flatten(), \n",
    "                           dataset[set_type][diff2_alpha][diff2_char][drawer2].flatten()])\n",
    "        labels.append(0)\n",
    "        \n",
    "    # Shuffle dataset\n",
    "    combined = list(zip(inputs, labels))\n",
    "    random.shuffle(combined)\n",
    "    \n",
    "    return zip(*combined)\n",
    "\n",
    "train_inputs, train_labels = get_random_dataset('images_background', 15000)\n",
    "valid_inputs, valid_labels = get_random_dataset('images_valid', 5000)\n",
    "test_inputs, test_labels = get_random_dataset('images_test', 5000)\n",
    "\n",
    "print(np.array(train_inputs).shape, np.array(train_labels).shape)\n",
    "print(np.array(valid_inputs).shape, np.array(valid_labels).shape)\n",
    "print(np.array(test_inputs).shape, np.array(test_labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABpCAAAAAAc6VLmAAABdklEQVR4nO2a0Q7DIAhFZdn//7J76GzXriAXSJcul4elyYynXFDUKr1dZI+rQCSl7FnYl7TWmpph/6geSRlTcs9Oo5D9o3okkUQSSSSRRBJJJJFEEkkk+cw6+ZD1qWIf6jtjGcwMETvNkQQMjpPMmxSRmgRZlnqrUIe+JaSgK06j50G0UOp/kHr9iDx/oQLSh3d4sNCM0GJXT7pwPK3BQp2KzLADhbFCc7mdgpWkECpYnwJ5Ea2EeFqEay7sVby6Lyi/U4l1BOhVesXiduoeqzBMvnv4dG5a4DKkrz5NOW+h3uKSOy0UUt+60jhXVMLB6Q3J9BhJxu8ZSHE28j03tttBSW9KH+rtrRvBg3c12wM4lyOk3QvDldBPynHcpL3+9bsaOVmXhFfLDp9Q2ZQm2sjdmu8cmoG6/i4Tn+A00NvYpOXze81HeF+cKs5YtDhlR8+3WbcWKjkO9couSUxIhZcxrOo+Hz6IxU5mInaLVRhJJJH0M9ILHfZA8pzv6egAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=105x105 at 0x7FC39D816A90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABpCAAAAAAc6VLmAAAA3UlEQVR4nO3ZQQ7DIAxEUVz1/lemi0ZqF4EwDLVa+r2LsnixTRIsopakuGVBSEhISEhIQtzbt6KUUtb9KHes3lf0aSJ6rd2xekhISEhISEhISK+42llG+5Y4HBg5Recp1krdhBdLEmWuCIG6WhHNth9GDK+L6ZyqOpca1XtSw/Xz39xRypG0+lk5SdSOX1gkJCQkJKTtpMTdcq40um1xpMSpJlf6/AQgh3qCct2bVpLGRH2mRLua7qlQ7V6+h9knYQbwJGXY6M2ppz2aPgwdn4jd+KFvBBISEhLSH0kPjaMX2dAdDRYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=105x105 at 0x7FC39D816B00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Atemayar_Qelisayer\n",
      "dict_keys(['character12', 'character25', 'character16', 'character26', 'character09', 'character22', 'character08', 'character06', 'character02', 'character19', 'character24', 'character14', 'character18', 'character04', 'character15', 'character03', 'character11', 'character13', 'character20', 'character23', 'character05', 'character01', 'character07', 'character17', 'character10', 'character21'])\n",
      "5 13\n",
      "character12\n",
      "20\n",
      "[[1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " ...\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "sample_idx = np.random.randint(len(train_inputs))\n",
    "display(Image.fromarray(np.reshape(train_inputs[sample_idx][0]*255, (105, 105))))\n",
    "display(Image.fromarray(np.reshape(train_inputs[sample_idx][1]*255, (105, 105))))\n",
    "print(train_labels[sample_idx])\n",
    "\n",
    "for alpha, char_set in dataset['images_test'].items():\n",
    "    print(alpha)\n",
    "    print(char_set.keys())\n",
    "    \n",
    "    drawer1 = np.random.randint(20)\n",
    "    drawer2 = drawer1\n",
    "    while drawer2 == drawer1:\n",
    "        drawer2 = np.random.randint(20)\n",
    "    \n",
    "    print(drawer1, drawer2)\n",
    "    \n",
    "    for char, samples in char_set.items():\n",
    "        print(char)\n",
    "        print(len(samples))\n",
    "        # Get two outputs per samples\n",
    "        print(samples[0])\n",
    "        break\n",
    "    \n",
    "    break\n",
    "    # Find most similar outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=10, padding=0),\n",
    "            # nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=7, padding=0),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=4, padding=0),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, padding=0),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.ReLU())\n",
    "        self.fc = nn.Linear(9216, 4096)\n",
    "        self.distance_fc = nn.Linear(4096, 1)\n",
    "    \n",
    "    def siamese_net(self, inputs):\n",
    "        inputs = inputs.view(-1, 1, 105, 105)\n",
    "        out = self.layer1(inputs)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        fc = self.fc(out.view(out.size(0), -1))\n",
    "        return fc\n",
    "    \n",
    "    def distance_layer(self, input1, input2):\n",
    "        return F.sigmoid(self.distance_fc(torch.abs(input1 - input2))).squeeze(1)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        out1 = self.siamese_net(x1)\n",
    "        out2 = self.siamese_net(x2)\n",
    "        # print(out1.size())\n",
    "        # print(out2.size())\n",
    "        distance = self.distance_layer(out1, out2)\n",
    "        # print(distance.size())\n",
    "        \n",
    "        return distance, out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Iter [1/30000] Loss: 0.6932\n",
      "Epoch [1/5], Iter [3841/30000] Loss: 0.6895\n",
      "Epoch [1/5], Iter [7681/30000] Loss: 0.5563\n",
      "Epoch [1/5], Iter [11521/30000] Loss: 0.4832\n",
      "Epoch [1/5], Iter [15361/30000] Loss: 0.5224\n",
      "Epoch [1/5], Iter [19201/30000] Loss: 0.4671\n",
      "Epoch [1/5], Iter [23041/30000] Loss: 0.5055\n",
      "Epoch [1/5], Iter [26881/30000] Loss: 0.5043\n",
      "Validation acc:0.7778876582278481 loss: 0.48886901668355437\n",
      "Atemayar_Qelisayer character12 character14 0.9360513687133789\n",
      "Atemayar_Qelisayer character25 character23 0.7150067687034607\n",
      "Atemayar_Qelisayer character16 character25 0.8135606050491333\n",
      "Atemayar_Qelisayer character26 character22 0.7368847131729126\n",
      "Atemayar_Qelisayer character09 character09 0.7636552453041077\n",
      "Atemayar_Qelisayer character22 character22 0.8158242106437683\n",
      "Atemayar_Qelisayer character08 character08 0.7727236151695251\n",
      "Atemayar_Qelisayer character06 character13 0.8522213101387024\n",
      "Atemayar_Qelisayer character02 character20 0.8007484674453735\n",
      "Atemayar_Qelisayer character19 character19 0.4238327145576477\n",
      "Atemayar_Qelisayer character24 character24 0.7331716418266296\n",
      "Atemayar_Qelisayer character14 character14 0.9167066812515259\n",
      "Atemayar_Qelisayer character18 character14 0.8540506958961487\n",
      "Atemayar_Qelisayer character04 character03 0.7979151606559753\n",
      "Atemayar_Qelisayer character15 character13 0.8593952059745789\n",
      "Atemayar_Qelisayer character03 character25 0.7988651394844055\n",
      "Atemayar_Qelisayer character11 character25 0.7832422852516174\n",
      "Atemayar_Qelisayer character13 character18 0.6071954369544983\n",
      "Atemayar_Qelisayer character20 character07 0.7408326268196106\n",
      "Atemayar_Qelisayer character23 character10 0.7552680373191833\n",
      "Atemayar_Qelisayer character05 character05 0.8200786113739014\n",
      "Atemayar_Qelisayer character01 character01 0.583747148513794\n",
      "Atemayar_Qelisayer character07 character16 0.8444899916648865\n",
      "Atemayar_Qelisayer character17 character02 0.7457001209259033\n",
      "Atemayar_Qelisayer character10 character08 0.8461448550224304\n",
      "Atemayar_Qelisayer character21 character13 0.7485718727111816\n",
      "Test one shot acc: 0.1596958174904943\n",
      "Epoch [2/5], Iter [1/30000] Loss: 0.4162\n",
      "Epoch [2/5], Iter [3841/30000] Loss: 0.4727\n",
      "Epoch [2/5], Iter [7681/30000] Loss: 0.3354\n",
      "Epoch [2/5], Iter [11521/30000] Loss: 0.3454\n",
      "Epoch [2/5], Iter [15361/30000] Loss: 0.3257\n",
      "Epoch [2/5], Iter [19201/30000] Loss: 0.2770\n",
      "Epoch [2/5], Iter [23041/30000] Loss: 0.3755\n",
      "Epoch [2/5], Iter [26881/30000] Loss: 0.3245\n",
      "Validation acc:0.7973694620253164 loss: 0.44294819990290873\n",
      "Atemayar_Qelisayer character12 character08 0.8734721541404724\n",
      "Atemayar_Qelisayer character25 character15 0.9737763404846191\n",
      "Atemayar_Qelisayer character16 character20 0.9851212501525879\n",
      "Atemayar_Qelisayer character26 character26 0.9538737535476685\n",
      "Atemayar_Qelisayer character09 character05 0.9384072422981262\n",
      "Atemayar_Qelisayer character22 character22 0.9702199697494507\n",
      "Atemayar_Qelisayer character08 character10 0.9952497482299805\n",
      "Atemayar_Qelisayer character06 character13 0.9556491374969482\n",
      "Atemayar_Qelisayer character02 character04 0.9883621335029602\n",
      "Atemayar_Qelisayer character19 character06 0.6599606275558472\n",
      "Atemayar_Qelisayer character24 character24 0.680999219417572\n",
      "Atemayar_Qelisayer character14 character14 0.9787067174911499\n",
      "Atemayar_Qelisayer character18 character21 0.7759715914726257\n",
      "Atemayar_Qelisayer character04 character12 0.984708309173584\n",
      "Atemayar_Qelisayer character15 character15 0.9251208305358887\n",
      "Atemayar_Qelisayer character03 character03 0.9676150679588318\n",
      "Atemayar_Qelisayer character11 character11 0.9675917029380798\n",
      "Atemayar_Qelisayer character13 character13 0.9660321474075317\n",
      "Atemayar_Qelisayer character20 character12 0.9821146130561829\n",
      "Atemayar_Qelisayer character23 character15 0.9851720333099365\n",
      "Atemayar_Qelisayer character05 character05 0.9533893465995789\n",
      "Atemayar_Qelisayer character01 character05 0.8753840327262878\n",
      "Atemayar_Qelisayer character07 character12 0.9660022258758545\n",
      "Atemayar_Qelisayer character17 character17 0.9381090998649597\n",
      "Atemayar_Qelisayer character10 character04 0.9821876287460327\n",
      "Atemayar_Qelisayer character21 character15 0.9781762957572937\n",
      "Test one shot acc: 0.25475285171102663\n",
      "Epoch [3/5], Iter [1/30000] Loss: 0.3927\n",
      "Epoch [3/5], Iter [3841/30000] Loss: 0.3343\n",
      "Epoch [3/5], Iter [7681/30000] Loss: 0.2131\n",
      "Epoch [3/5], Iter [11521/30000] Loss: 0.2028\n",
      "Epoch [3/5], Iter [15361/30000] Loss: 0.2569\n",
      "Epoch [3/5], Iter [19201/30000] Loss: 0.2005\n",
      "Epoch [3/5], Iter [23041/30000] Loss: 0.2519\n",
      "Epoch [3/5], Iter [26881/30000] Loss: 0.2416\n",
      "Validation acc:0.8666930379746836 loss: 0.3272584457940693\n",
      "Atemayar_Qelisayer character12 character12 0.992965579032898\n",
      "Atemayar_Qelisayer character25 character20 0.9958705306053162\n",
      "Atemayar_Qelisayer character16 character02 0.8588923215866089\n",
      "Atemayar_Qelisayer character26 character08 0.9677831530570984\n",
      "Atemayar_Qelisayer character09 character09 0.9720247983932495\n",
      "Atemayar_Qelisayer character22 character02 0.9882903099060059\n",
      "Atemayar_Qelisayer character08 character08 0.9563717246055603\n",
      "Atemayar_Qelisayer character06 character12 0.9959509372711182\n",
      "Atemayar_Qelisayer character02 character11 0.9723237156867981\n",
      "Atemayar_Qelisayer character19 character15 0.9811919331550598\n",
      "Atemayar_Qelisayer character24 character24 0.9167211055755615\n",
      "Atemayar_Qelisayer character14 character13 0.9972180128097534\n",
      "Atemayar_Qelisayer character18 character18 0.9796800017356873\n",
      "Atemayar_Qelisayer character04 character08 0.9632587432861328\n",
      "Atemayar_Qelisayer character15 character13 0.9978260397911072\n",
      "Atemayar_Qelisayer character03 character08 0.9884099960327148\n",
      "Atemayar_Qelisayer character11 character11 0.9885204434394836\n",
      "Atemayar_Qelisayer character13 character13 0.9991740584373474\n",
      "Atemayar_Qelisayer character20 character02 0.9900121092796326\n",
      "Atemayar_Qelisayer character23 character06 0.9845074415206909\n",
      "Atemayar_Qelisayer character05 character22 0.855064332485199\n",
      "Atemayar_Qelisayer character01 character01 0.9594153761863708\n",
      "Atemayar_Qelisayer character07 character08 0.9887576699256897\n",
      "Atemayar_Qelisayer character17 character14 0.959354043006897\n",
      "Atemayar_Qelisayer character10 character17 0.9880917072296143\n",
      "Atemayar_Qelisayer character21 character13 0.9872205853462219\n",
      "Test one shot acc: 0.311787072243346\n",
      "Epoch [4/5], Iter [1/30000] Loss: 0.1564\n",
      "Epoch [4/5], Iter [3841/30000] Loss: 0.2224\n",
      "Epoch [4/5], Iter [7681/30000] Loss: 0.1906\n",
      "Epoch [4/5], Iter [11521/30000] Loss: 0.1501\n",
      "Epoch [4/5], Iter [15361/30000] Loss: 0.1954\n",
      "Epoch [4/5], Iter [19201/30000] Loss: 0.2346\n",
      "Epoch [4/5], Iter [23041/30000] Loss: 0.1884\n",
      "Epoch [4/5], Iter [26881/30000] Loss: 0.1868\n",
      "Validation acc:0.8758900316455697 loss: 0.34286498240654983\n",
      "Atemayar_Qelisayer character12 character12 0.9915207028388977\n",
      "Atemayar_Qelisayer character25 character11 0.9998087286949158\n",
      "Atemayar_Qelisayer character16 character17 0.9078733325004578\n",
      "Atemayar_Qelisayer character26 character10 0.9919359683990479\n",
      "Atemayar_Qelisayer character09 character09 0.9521913528442383\n",
      "Atemayar_Qelisayer character22 character07 0.998572826385498\n",
      "Atemayar_Qelisayer character08 character08 0.98649001121521\n",
      "Atemayar_Qelisayer character06 character06 0.999871015548706\n",
      "Atemayar_Qelisayer character02 character20 0.9990440011024475\n",
      "Atemayar_Qelisayer character19 character15 0.998955488204956\n",
      "Atemayar_Qelisayer character24 character24 0.9997201561927795\n",
      "Atemayar_Qelisayer character14 character14 0.9999443292617798\n",
      "Atemayar_Qelisayer character18 character18 0.9978798627853394\n",
      "Atemayar_Qelisayer character04 character04 0.999854326248169\n",
      "Atemayar_Qelisayer character15 character14 0.9990697503089905\n",
      "Atemayar_Qelisayer character03 character04 0.99410480260849\n",
      "Atemayar_Qelisayer character11 character03 0.9799938201904297\n",
      "Atemayar_Qelisayer character13 character13 0.9964806437492371\n",
      "Atemayar_Qelisayer character20 character02 0.9968962669372559\n",
      "Atemayar_Qelisayer character23 character14 0.9997790455818176\n",
      "Atemayar_Qelisayer character05 character05 0.9904386401176453\n",
      "Atemayar_Qelisayer character01 character01 0.9698576331138611\n",
      "Atemayar_Qelisayer character07 character20 0.9979438185691833\n",
      "Atemayar_Qelisayer character17 character18 0.9956089854240417\n",
      "Atemayar_Qelisayer character10 character23 0.9867839813232422\n",
      "Atemayar_Qelisayer character21 character15 0.99367356300354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test one shot acc: 0.2889733840304182\n",
      "Epoch [5/5], Iter [1/30000] Loss: 0.0561\n",
      "Epoch [5/5], Iter [3841/30000] Loss: 0.1600\n",
      "Epoch [5/5], Iter [7681/30000] Loss: 0.1542\n",
      "Epoch [5/5], Iter [11521/30000] Loss: 0.0542\n",
      "Epoch [5/5], Iter [15361/30000] Loss: 0.1488\n",
      "Epoch [5/5], Iter [19201/30000] Loss: 0.0808\n",
      "Epoch [5/5], Iter [23041/30000] Loss: 0.1759\n",
      "Epoch [5/5], Iter [26881/30000] Loss: 0.1607\n",
      "Validation acc:0.8509691455696202 loss: 0.5156292738039282\n",
      "Atemayar_Qelisayer character12 character13 0.9997777342796326\n",
      "Atemayar_Qelisayer character25 character06 0.9999542236328125\n",
      "Atemayar_Qelisayer character16 character16 0.9989928603172302\n",
      "Atemayar_Qelisayer character26 character08 0.9983616471290588\n",
      "Atemayar_Qelisayer character09 character09 0.9999353885650635\n",
      "Atemayar_Qelisayer character22 character22 0.9999037981033325\n",
      "Atemayar_Qelisayer character08 character11 0.9723525643348694\n",
      "Atemayar_Qelisayer character06 character17 0.9998070597648621\n",
      "Atemayar_Qelisayer character02 character07 0.9999496936798096\n",
      "Atemayar_Qelisayer character19 character21 0.9944064617156982\n",
      "Atemayar_Qelisayer character24 character24 0.9998759031295776\n",
      "Atemayar_Qelisayer character14 character14 0.9999217987060547\n",
      "Atemayar_Qelisayer character18 character23 0.9999854564666748\n",
      "Atemayar_Qelisayer character04 character25 0.9999790191650391\n",
      "Atemayar_Qelisayer character15 character13 0.9999356269836426\n",
      "Atemayar_Qelisayer character03 character22 0.999984622001648\n",
      "Atemayar_Qelisayer character11 character16 0.9997249245643616\n",
      "Atemayar_Qelisayer character13 character13 0.9997971653938293\n",
      "Atemayar_Qelisayer character20 character11 0.9999351501464844\n",
      "Atemayar_Qelisayer character23 character07 0.9989508390426636\n",
      "Atemayar_Qelisayer character05 character05 0.999975323677063\n",
      "Atemayar_Qelisayer character01 character01 0.9986775517463684\n",
      "Atemayar_Qelisayer character07 character11 0.9993588328361511\n",
      "Atemayar_Qelisayer character17 character04 0.9999426603317261\n",
      "Atemayar_Qelisayer character10 character10 0.9988034963607788\n",
      "Atemayar_Qelisayer character21 character21 0.9999444484710693\n",
      "Test one shot acc: 0.30038022813688214\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN().cuda()\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-1, momentum=0.5)\n",
    "\n",
    "num_epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    cnn.train(True)\n",
    "    \n",
    "    for train_idx in range(0, len(train_inputs), batch_size):\n",
    "        batch_inputs = train_inputs[train_idx:train_idx+batch_size]\n",
    "        batch_input1 = [b[0] for b in batch_inputs]\n",
    "        batch_input2 = [b[1] for b in batch_inputs]\n",
    "        batch_labels = train_labels[train_idx:train_idx+batch_size]\n",
    "        # print(np.array(batch_input1).shape)\n",
    "        # print(np.array(batch_input2).shape)\n",
    "        # print(np.array(batch_label).shape)\n",
    "        input1 = Variable(torch.Tensor(np.array(batch_input1).astype(np.float32))).cuda(0)\n",
    "        input2 = Variable(torch.Tensor(np.array(batch_input2).astype(np.float32))).cuda(0)\n",
    "        labels = Variable(torch.Tensor(np.array(batch_labels).astype(np.float32))).cuda(0)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _, _ = cnn(input1, input2)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (train_idx) % (batch_size * 30) == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, train_idx+1, len(train_inputs), loss.data[0]))\n",
    "    \n",
    "    # Validation\n",
    "    cnt = 0\n",
    "    acc = 0.\n",
    "    losses = 0.\n",
    "    cnn.train(False)\n",
    "    for valid_idx in range(0, len(valid_inputs), batch_size):\n",
    "        batch_inputs = valid_inputs[valid_idx:valid_idx+batch_size]\n",
    "        batch_input1 = [b[0] for b in batch_inputs]\n",
    "        batch_input2 = [b[1] for b in batch_inputs]\n",
    "        batch_labels = valid_labels[valid_idx:valid_idx+batch_size]\n",
    "        # print(np.array(batch_input1).shape)\n",
    "        # print(np.array(batch_input2).shape)\n",
    "        # print(np.array(batch_label).shape)\n",
    "        input1 = Variable(torch.Tensor(np.array(batch_input1).astype(np.float32))).cuda(0)\n",
    "        input2 = Variable(torch.Tensor(np.array(batch_input2).astype(np.float32))).cuda(0)\n",
    "        labels = Variable(torch.Tensor(np.array(batch_labels).astype(np.float32))).cuda(0)\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        outputs, _, _ = cnn(input1, input2)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        outputs = [int(k > 0.5) for k in outputs.data.tolist()]\n",
    "        acc += sum([o == l for o, l in zip(outputs, batch_labels)])/input1.size(0)\n",
    "        losses += loss.data[0]\n",
    "        cnt += 1\n",
    "        \n",
    "    print('Validation acc:{} loss: {}'.format(acc/cnt, losses/cnt))\n",
    "    \n",
    "    cnt = 0\n",
    "    acc = 0.\n",
    "    for alpha, char_set in dataset['images_test'].items():\n",
    "        # Select two drawers\n",
    "        drawer1 = np.random.randint(20)\n",
    "        drawer2 = drawer1\n",
    "        while drawer2 == drawer1:\n",
    "            drawer2 = np.random.randint(20)\n",
    "        \n",
    "        sim_dict = {}\n",
    "        for char1, samples1 in char_set.items():\n",
    "            sim_dict[char1] = PriorityQueue()\n",
    "            for char2, samples2 in char_set.items():\n",
    "                input1 = Variable(torch.Tensor(np.array([samples1[drawer1]]).astype(np.float32))).cuda(0)\n",
    "                input2 = Variable(torch.Tensor(np.array([samples2[drawer2]]).astype(np.float32))).cuda(0)\n",
    "                distance, _, _ = cnn(input1, input2)\n",
    "                sim_dict[char1].put((-distance.data[0], char2))\n",
    "            \n",
    "            score, predicted = sim_dict[char1].get()\n",
    "            if alpha == 'Atemayar_Qelisayer':\n",
    "                print(alpha, char1, predicted, -score)\n",
    "            if predicted == char1:\n",
    "                acc += 1\n",
    "            cnt += 1\n",
    "    print('Test one shot acc: {}'.format(acc/cnt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d9a0e5aa7417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamples1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdrawer1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0minput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamples2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdrawer2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0msim_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "drawer1 = np.random.randint(20)\n",
    "drawer2 = drawer1\n",
    "while drawer2 == drawer1:\n",
    "    drawer2 = np.random.randint(20)\n",
    "\n",
    "for alpha, char_set in dataset['images_test'].items():\n",
    "    sim_dict = {}\n",
    "    sample1_img = {}\n",
    "    sample2_img = {}\n",
    "    for char1, samples1 in char_set.items():\n",
    "        sim_dict[char1] = {}\n",
    "        sample1_img[char1] = samples1[drawer1]\n",
    "        for char2, samples2 in char_set.items():\n",
    "            sample2_img[char2] = samples2[drawer2]\n",
    "            input1 = Variable(torch.Tensor(np.array([samples1[drawer1]]).astype(np.float32))).cuda(0)\n",
    "            input2 = Variable(torch.Tensor(np.array([samples2[drawer2]]).astype(np.float32))).cuda(0)\n",
    "            distance, _, _ = cnn(input1, input2)\n",
    "            sim_dict[char1][char2] = -distance.data[0]\n",
    "\n",
    "        \n",
    "        if alpha == 'Korean':\n",
    "            display(Image.fromarray(sample1_img[char1]*255))\n",
    "            print('Test image {}'.format(char1))\n",
    "            \n",
    "            for key, val in sample2_img.items():\n",
    "                score = sim_dict[char1][key]\n",
    "                display(Image.fromarray(val*255))\n",
    "                print(key, -score)\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
